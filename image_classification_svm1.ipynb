{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41bc625b",
      "metadata": {
        "id": "41bc625b"
      },
      "source": [
        "# Image Classification using SVM\n",
        "This notebook demonstrates how to classify image datasets using a Support Vector Machine (SVM). We will use the MNIST dataset from TensorFlow and a Fruits-360 dataset from Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745542d7",
      "metadata": {
        "id": "745542d7"
      },
      "source": [
        "## Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "01b8b94d",
      "metadata": {
        "id": "01b8b94d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb538069",
      "metadata": {
        "id": "bb538069"
      },
      "source": [
        "## Step 2: Load and Preprocess MNIST Dataset\n",
        "The MNIST dataset consists of 70,000 images of handwritten digits (0-9). Each image is 28x28 pixels in grayscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e1d4a4e",
      "metadata": {
        "id": "5e1d4a4e",
        "outputId": "df106597-55d0-4dbc-c5d8-9dabcb468d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "MNIST Dataset Sample:\n",
            "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   778  779  780  781  782  783  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "6  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "7  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "8  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "9  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[10 rows x 784 columns]\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0,1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Flatten images for SVM\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "print(\"MNIST Dataset Sample:\")\n",
        "print(pd.DataFrame(X_train).head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c50152a",
      "metadata": {
        "id": "0c50152a"
      },
      "source": [
        "## Step 3: Load Image Dataset from Kaggle\n",
        "Using the Kaggle API to download an image dataset. Make sure you have configured Kaggle API credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "06e1c072",
      "metadata": {
        "id": "06e1c072",
        "outputId": "5bbe86b8-c73d-402e-b69b-c6f51194ead4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/moltean/fruits\n"
          ]
        }
      ],
      "source": [
        "api = KaggleApi()\n",
        "#api.authenticate()\n",
        "\n",
        "# Download the dataset\n",
        "dataset_path = './fruits'\n",
        "api.dataset_download_files('moltean/fruits', path=dataset_path, unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53eb923a",
      "metadata": {
        "id": "53eb923a"
      },
      "source": [
        "## Step 4: Process Images\n",
        "We load images, resize them to (32x32), convert to grayscale, and flatten them for SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a21c3f3e",
      "metadata": {
        "id": "a21c3f3e"
      },
      "outputs": [],
      "source": [
        "image_folder = os.path.join(dataset_path, '/content/fruits/fruits-360_100x100/fruits-360/Training')\n",
        "image_size = (32, 32)\n",
        "X_images = []\n",
        "y_labels = []\n",
        "label_map = {}\n",
        "label_index = 0\n",
        "\n",
        "for category in os.listdir(image_folder):\n",
        "    category_path = os.path.join(image_folder, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        if category not in label_map:\n",
        "            label_map[category] = label_index\n",
        "            label_index += 1\n",
        "        for image_file in os.listdir(category_path):\n",
        "            image_path = os.path.join(category_path, image_file)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image, image_size)\n",
        "                X_images.append(image.flatten())\n",
        "                y_labels.append(label_map[category])\n",
        "\n",
        "X_images = np.array(X_images) / 255.0\n",
        "y_labels = np.array(y_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ecf82e",
      "metadata": {
        "id": "e7ecf82e"
      },
      "source": [
        "## Step 5: Split Data into Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fd24c7e8",
      "metadata": {
        "id": "fd24c7e8"
      },
      "outputs": [],
      "source": [
        "X_train_fruits, X_test_fruits, y_train_fruits, y_test_fruits = train_test_split(\n",
        "    X_images, y_labels, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98f4edc",
      "metadata": {
        "id": "b98f4edc"
      },
      "source": [
        "## Step 6: Train an SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19290709",
      "metadata": {
        "id": "19290709"
      },
      "outputs": [],
      "source": [
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train_fruits, y_train_fruits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdfebf3c",
      "metadata": {
        "id": "cdfebf3c"
      },
      "source": [
        "## Step 7: Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b94bde",
      "metadata": {
        "id": "b9b94bde"
      },
      "outputs": [],
      "source": [
        "y_pred_fruits = svm_model.predict(X_test_fruits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbec31fc",
      "metadata": {
        "id": "dbec31fc"
      },
      "source": [
        "## Step 8: Evaluate the Model\n",
        "We calculate accuracy, precision, recall, and display the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b83d7cb",
      "metadata": {
        "id": "3b83d7cb"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test_fruits, y_pred_fruits)\n",
        "precision = precision_score(y_test_fruits, y_pred_fruits, average='weighted', zero_division=1)\n",
        "recall = recall_score(y_test_fruits, y_pred_fruits, average='weighted', zero_division=1)\n",
        "conf_matrix = confusion_matrix(y_test_fruits, y_pred_fruits)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}