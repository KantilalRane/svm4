{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# **Image Classification using SVM with TensorFlow**\n", "This notebook demonstrates how to use **Support Vector Machines (SVM)** for image classification by extracting features from a pre-trained **MobileNetV2** model in TensorFlow."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\n", "import numpy as np\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras.applications import MobileNetV2\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras.layers import GlobalAveragePooling2D\n", "from sklearn.svm import SVC\n", "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n", "import matplotlib.pyplot as plt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **1. Load and Preprocess Data**\n", "- We use **Fashion MNIST**, a dataset of grayscale 28x28 images.\n", "- Images are **normalized** to [0,1] and resized to **96x96** to match MobileNetV2 input size.\n", "- Convert grayscale images to **3 channels** (RGB)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load Fashion MNIST dataset\n", "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n", "\n", "# Normalize images\n", "x_train = x_train / 255.0\n", "x_test = x_test / 255.0\n", "\n", "# Resize images to match MobileNetV2 input size\n", "x_train_resized = np.stack([tf.image.resize(img[..., np.newaxis], (96, 96)).numpy() for img in x_train])\n", "x_test_resized = np.stack([tf.image.resize(img[..., np.newaxis], (96, 96)).numpy() for img in x_test])\n", "\n", "# Convert grayscale images to 3 channels\n", "x_train_resized = np.repeat(x_train_resized, 3, axis=-1)\n", "x_test_resized = np.repeat(x_test_resized, 3, axis=-1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **2. Feature Extraction using MobileNetV2**\n", "We load a **pre-trained MobileNetV2 model** (without its top classification layer) to extract meaningful features from images."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load pre-trained MobileNetV2 model without the classification head\n", "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(96, 96, 3))\n", "\n", "# Extract features using Global Average Pooling\n", "x = base_model.output\n", "x = GlobalAveragePooling2D()(x)\n", "feature_extractor = Model(inputs=base_model.input, outputs=x)\n", "\n", "# Extract features for train and test sets\n", "train_features = feature_extractor.predict(x_train_resized)\n", "test_features = feature_extractor.predict(x_test_resized)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **3. Train SVM Classifier**\n", "Now, we train an **SVM classifier** using the extracted features."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train SVM classifier\n", "svm_clf = SVC(kernel='linear', C=1.0)\n", "svm_clf.fit(train_features, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **4. Evaluate Model Performance**\n", "We assess the model's accuracy and performance using a confusion matrix and classification report."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make predictions\n", "y_pred = svm_clf.predict(test_features)\n", "\n", "# Compute accuracy\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f\"Model Accuracy: {accuracy:.4f}\")\n", "\n", "# Print classification report\n", "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n", "\n", "# Print confusion matrix\n", "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **5. Visualize Some Predictions**\n", "We display a few test images with their predicted and actual labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize some test images with predicted labels\n", "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n", "for ax, image, label, pred in zip(axes.ravel(), x_test[:10], y_test[:10], y_pred[:10]):\n", "    ax.set_axis_off()\n", "    ax.imshow(image, cmap='gray')\n", "    ax.set_title(f\"Label: {label}\\nPred: {pred}\")\n", "\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Conclusion**\n", "We successfully used **MobileNetV2** to extract deep features and trained an **SVM classifier** for image classification."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}