{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bc625b",
   "metadata": {},
   "source": [
    "# Image Classification using SVM\n",
    "This notebook demonstrates how to classify image datasets using a Support Vector Machine (SVM). We will use the MNIST dataset from TensorFlow and a Fruits-360 dataset from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745542d7",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb538069",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess MNIST Dataset\n",
    "The MNIST dataset consists of 70,000 images of handwritten digits (0-9). Each image is 28x28 pixels in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0,1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Flatten images for SVM\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(\"MNIST Dataset Sample:\")\n",
    "print(pd.DataFrame(X_train).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50152a",
   "metadata": {},
   "source": [
    "## Step 3: Load Image Dataset from Kaggle\n",
    "Using the Kaggle API to download an image dataset. Make sure you have configured Kaggle API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download the dataset\n",
    "dataset_path = './fruits'\n",
    "api.dataset_download_files('moltean/fruits', path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb923a",
   "metadata": {},
   "source": [
    "## Step 4: Process Images\n",
    "We load images, resize them to (32x32), convert to grayscale, and flatten them for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = os.path.join(dataset_path, 'fruits-360/Training')\n",
    "image_size = (32, 32)\n",
    "X_images = []\n",
    "y_labels = []\n",
    "label_map = {}\n",
    "label_index = 0\n",
    "\n",
    "for category in os.listdir(image_folder):\n",
    "    category_path = os.path.join(image_folder, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        if category not in label_map:\n",
    "            label_map[category] = label_index\n",
    "            label_index += 1\n",
    "        for image_file in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, image_file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, image_size)\n",
    "                X_images.append(image.flatten())\n",
    "                y_labels.append(label_map[category])\n",
    "\n",
    "X_images = np.array(X_images) / 255.0\n",
    "y_labels = np.array(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecf82e",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fruits, X_test_fruits, y_train_fruits, y_test_fruits = train_test_split(\n",
    "    X_images, y_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f4edc",
   "metadata": {},
   "source": [
    "## Step 6: Train an SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19290709",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_fruits, y_train_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfebf3c",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b94bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fruits = svm_model.predict(X_test_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec31fc",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate the Model\n",
    "We calculate accuracy, precision, recall, and display the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_fruits, y_pred_fruits)\n",
    "precision = precision_score(y_test_fruits, y_pred_fruits, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test_fruits, y_pred_fruits, average='weighted', zero_division=1)\n",
    "conf_matrix = confusion_matrix(y_test_fruits, y_pred_fruits)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
