{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ac26b8",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fa6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abb4c6",
   "metadata": {},
   "source": [
    "## Step 2: Load and Normalize the Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd7b5d",
   "metadata": {},
   "source": [
    "## Step 3: Resize Images and Convert to 3 Channels (Fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_repeat(image):\n",
    "    image = tf.expand_dims(image, axis=-1)  # Add a channel dimension (28,28) -> (28,28,1)\n",
    "    image_resized = tf.image.resize(image, (96, 96))  # Resize to 96x96\n",
    "    image_resized = tf.repeat(image_resized, 3, axis=-1)  # Convert to 3 channels\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387b1be",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Data Using tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_data, y_data):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "    dataset = dataset.map(lambda x, y: (resize_and_repeat(x), y))\n",
    "    dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "train_dataset = preprocess_data(x_train, y_train)\n",
    "test_dataset = preprocess_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bb1b7",
   "metadata": {},
   "source": [
    "## Step 5: Load Pre-trained MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a254ca",
   "metadata": {},
   "source": [
    "## Step 6: Create Feature Extractor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b53b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d0edc",
   "metadata": {},
   "source": [
    "## Step 7: Extract Features Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_labels)\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "train_features, y_train_extracted = extract_features(train_dataset)\n",
    "test_features, y_test_extracted = extract_features(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe9fa3",
   "metadata": {},
   "source": [
    "## Step 8: Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='linear', C=1.0)\n",
    "svm_clf.fit(train_features, y_train_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb579c",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62ad41",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc152ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_extracted, y_pred)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')\n",
    "print('\\nClassification Report:\\n', classification_report(y_test_extracted, y_pred))\n",
    "print('\\nConfusion Matrix:\\n', confusion_matrix(y_test_extracted, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938949a5",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for ax, image, label, pred in zip(axes.ravel(), x_test[:10], y_test[:10], y_pred[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Label: {label}\\nPred: {pred}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fad1b3",
   "metadata": {},
   "source": [
    "## Step 12: Save Extracted Features and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "feature_path = 'train_features.npy'\n",
    "test_feature_path = 'test_features.npy'\n",
    "svm_model_path = 'svm_classifier.pkl'\n",
    "\n",
    "# Save extracted features\n",
    "np.save(feature_path, train_features)\n",
    "np.save(test_feature_path, test_features)\n",
    "\n",
    "# Save the trained SVM model\n",
    "joblib.dump(svm_clf, svm_model_path)\n",
    "print('Model and features saved successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bd9ee",
   "metadata": {},
   "source": [
    "## Step 13: Load Model and Features When Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved features and model\n",
    "train_features_loaded = np.load('train_features.npy')\n",
    "test_features_loaded = np.load('test_features.npy')\n",
    "svm_clf_loaded = joblib.load('svm_classifier.pkl')\n",
    "print('Model and features loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae80035",
   "metadata": {},
   "source": [
    "## Step 14: Use the Loaded Model for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_loaded = svm_clf_loaded.predict(test_features_loaded)\n",
    "accuracy_loaded = accuracy_score(y_test_extracted, y_pred_loaded)\n",
    "print(f'Loaded Model Accuracy: {accuracy_loaded:.4f}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
