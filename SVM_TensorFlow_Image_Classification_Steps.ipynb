{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f51a54",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b598f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9779bf",
   "metadata": {},
   "source": [
    "## Step 2: Load and Normalize the Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a312da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551e4f1",
   "metadata": {},
   "source": [
    "## Step 3: Resize Images and Convert to 3 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_repeat(image):\n",
    "    image_resized = tf.image.resize(image, (96, 96))\n",
    "    image_resized = tf.repeat(image_resized, 3, axis=-1)\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951ff22",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Data Using tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_data, y_data):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "    dataset = dataset.map(lambda x, y: (resize_and_repeat(x), y))\n",
    "    dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "train_dataset = preprocess_data(x_train, y_train)\n",
    "test_dataset = preprocess_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242f7c6",
   "metadata": {},
   "source": [
    "## Step 5: Load Pre-trained MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30601b4",
   "metadata": {},
   "source": [
    "## Step 6: Create Feature Extractor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c5a58",
   "metadata": {},
   "source": [
    "## Step 7: Extract Features Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63462a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_labels)\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "train_features, y_train_extracted = extract_features(train_dataset)\n",
    "test_features, y_test_extracted = extract_features(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705d4f9",
   "metadata": {},
   "source": [
    "## Step 8: Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58877dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='linear', C=1.0)\n",
    "svm_clf.fit(train_features, y_train_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30247b5c",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2702530",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09d0f5",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c42b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_extracted, y_pred)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')\n",
    "print('\\nClassification Report:\\n', classification_report(y_test_extracted, y_pred))\n",
    "print('\\nConfusion Matrix:\\n', confusion_matrix(y_test_extracted, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82333d",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab620677",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for ax, image, label, pred in zip(axes.ravel(), x_test[:10], y_test[:10], y_pred[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Label: {label}\\nPred: {pred}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
